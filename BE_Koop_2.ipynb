{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNbArROR5FUm6II5tKXPNq2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dandoreyrodriguez/Bayesian_Econometrics/blob/main/BE_Koop_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Class 2 in Bayesian Econometrics**\n",
        "\n",
        "## **Motivation**\n",
        "\n",
        "Last class we learned Bayesian basics. Its glory is its generality! We also saw why doing Bayes is hard: because getting the right scaling constant for the posterior distribution often involves nasty integrals which may not have nice, recognisable analytical solutions. Moreover, numerical approximations of integrals scale poorly as you move to high-dimensional space. We got around this by choosing *conjugate* priors which gave us the same easily recognisable integrals.\n",
        "\n",
        "Today we are in Monaco, doing MONTE CARLO MARKOV CHAINS (MCMC)! It turns out that we can construct special stochastic processes, called Markov chains, from which we can sample our vector of parameters $\\boldsymbol{\\theta}$, which will converge to behave as if being sampled from the true posterior! Once we have this, applying the law of large numbers (LLN) is just a small step away! As during our frequentist days, the LLN will be our best friend. Although now in our Bayesian era, we won't be bound by the sample size. Instead, we can control how many samples to take. This surely makes the LLN not just a good friend, but a more trustworthy friend. Join me to see how randomness will be the maker of our statistical fortunes...\n",
        "\n"
      ],
      "metadata": {
        "id": "TEpMFEvOwHj-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Markov Chains**\n",
        "\n",
        "A Markov chain is a particular kind of stochastic process. A stochastic process is collection of random variable vectors indexed by $t$, $\\{\\boldsymbol{v}^{(t)}\\}_{t=0}^T$. If $q$ represents the relevant probability distribution, a stochastic process is a Markov chain if and only if:\n",
        "\n",
        "$$q(\\boldsymbol{v}^{(t+1)}|\\boldsymbol{v}^{(t)}, ...,\\boldsymbol{v}^{(0)}) = q(\\boldsymbol{v}^{(t+1)}|\\boldsymbol{v}^{(t)}), \\forall t \\in \\{0, ..., T\\} $$\n",
        "\n",
        "Some Markov chains have a very special property, they may converge to a *stationary* distributions. That is, once you have a *stationary* (marginal) distribution, the Markov chain keeps that distribution. That is, the next draw has the same distribution. The same happens at the next draw. And so forth. This gives the system some stability, where the chain no longer depends on its state.\n",
        "\n",
        "More formally, a stationary distribution, $\\pi$, is a probability distribution such that:\n",
        "\n",
        "$$\\pi (\\boldsymbol{\\theta}^{(t+1)}) = \\int q(\\boldsymbol{\\theta}^{(t+1)}|\\boldsymbol{\\theta}^{(t)})\\pi( \\boldsymbol{\\theta}^{(t)} ) d \\boldsymbol{\\theta}^{(t)}, \\forall t \\in \\{0, ..., T\\}$$\n",
        "\n",
        "Hang on a second...what if we had a Markov chain which had the true posterior, $f(\\boldsymbol{\\theta}|\\boldsymbol{y})$, as a stationary distribution? Then all we would need is to set this Markov chain, which always converged to this stationary distribution from a valid starting point, turning the problem into a sampling problem. That would be riotous gamble. We would be able to sidestep pesky integration. But this seems too good to be true. This surprising application of MCMCs is, to me, an example of the \"unreasonable effectiveness\" of computational methods.\n"
      ],
      "metadata": {
        "id": "9UlpDpzt8U8v"
      }
    }
  ]
}